<!DOCTYPE html>
<html>
<head>
    <title>Project 5</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 20px;
        }
    </style>
    <style>
        table {
            width: 80%;
            border-collapse: collapse;
            margin: 20px auto;
        }
        td {
            text-align: center;
            padding: 10px;
        }
        img {
            width: 100%;
            height: auto;
        }
        caption {
            font-size: 1.2em;
            font-weight: bold;
            padding: 10px;
        }
        .caption {
            font-weight: bold;
            font-size: 1em;
            padding-top: 5px;
        }
    </style>
</head>
<body>
    <div class="navbar clear nav-top">
        <div class="row" style="text-align: center;">
            <h1> Project 5: Fun With Diffusion Models! </h1>
        </div>
    </div>
    
    <h1> Project 5A: The Power of Diffusion Models! </h1>

    <h2> Background </h2>
    <p> 
        In Part A, we play with diffusion models, implement diffusion sampling loops, and use them for other tasks such as inpainting and creating optical illusions. We use the DeepFloydIF diffusion model to help run the code.
    </p>

    <h2> 0. Sampling from the Model </h2>
    <h3> Approach </h3>
    <p>
        In this part, I used <code>num_inference_steps=20</code> for Stage 1 and <code>num_inference_steps=5</code> for Stage 2. The images are shown below.
    </p>
    <img src="media5a/part0model2changedto5.jpg" style="width:300px;height:auto;" alt="part0model2changedto5.jpg">
    <div class="caption"> Stage 1 with <code>num_inference_steps=20</code> (Top) and Stage 2 with <code>num_inference_steps=5</code> (Bottom) </div>

    <h2> 1.1 Implementing the Forward Process </h2>
    <h3> Approach </h3>
    <p>
        In order to implement forward process, I created a <code>forward</code> function that applies the equations to the test image on the project spec. The results are shown below.
    </p>
    <img src="media5a/part1.1.jpg" style="width:300px;height:auto;" alt="part1.1.jpg">
    <div class="caption"> Test Images at Noise Levels 250, 500 and 750 </div>

    <h2> 1.2 Classical Denoising </h2>
    <h3> Approach </h3>
    <p>
        In this part, I applied <code>torchvision.transforms.functional.gaussian_blur</code> to each of the noisy images from the previous part. The results are shown below, with the top image being the noisy image and the bottom being the denoised.
    </p>
    <table border="1">
        <tr>
            <td>
                <img src="media5a/part1.2t250.jpg" style="width:300px;height:auto;" alt="part1.2t250.jpg">
            </td>
            <td>
                <img src="media5a/part1.2t500.jpg" style="width:300px;height:auto;" alt="part1.2t500.jpg">
            </td>
            <td>
                <img src="media5a/part1.2t750.jpg" style="width:300px;height:auto;" alt="part1.2t750.jpg">
            </td>
        </tr>
    </table>

    <h2> 1.3 One-Step Denoising </h2>
    <h3> Approach </h3>
    <p>
        In order to one-step denoise, I first applied the forward process to the test image then passed it through <code>stage_1.unet</code>. Then, I used the equation <code>(im_noisy - noise_est * torch.sqrt(1 - alpha_cumprod)) / torch.sqrt(alpha_cumprod)</code> to remove the noise from the image. The results are shown below:
    </p>
    <table border="1">
        <tr>
            <td>
                <img src="media5a/part1.3t250.jpg" style="width:300px;height:auto;" alt="part1.3t250.jpg">
            </td>
            <td>
                <img src="media5a/part1.3t500.jpg" style="width:300px;height:auto;" alt="part1.3t500.jpg">
            </td>
            <td>
                <img src="media5a/part1.3t730.jpg" style="width:300px;height:auto;" alt="part1.3t730.jpg">
            </td>
        </tr>
    </table>

    <h2> 1.4 Iterative Denoising </h2>
    <h3> Approach </h3>
    <p>
        To iteratively denoise, I applied equations 6 and 7 of the DDPM paper in the project spec, with strided timesteps from <code>990</code> to <code>0</code>. The results are displayed below:
    </p>
    <table border="1">
        <tr>
            <td>
                <img src="media5a/part1.4iter690-390.jpg" style="width:300px;height:auto;" alt="part1.4iter690-390.jpg">
                <img src="media5a/part1.4iter240-clean.jpg" style="width:300px;height:auto;" alt="part1.4iter240-clean.jpg">
                <div class="caption"> Noisy Campanile at <code>t=690</code> to <code>0</code> </div>
            </td>
            <td>
                <img src="media5a/part1.4onestepandgauss.jpg" style="width:300px;height:auto;" alt="part1.4onestepandgauss.jpg">
                <div class="caption"> Single Denoising Step (Top) and Gaussian Blurring (Bottom) </div>
            </td>
        </tr>
    </table>

    <h2> 1.5 Diffusion Model Sampling </h2>
    <h3> Approach </h3>
    <p>
        To generate images from scratch, I generated random noise with <code>torch.randn</code> and applied my <code>iterative_denoise</code> function on it. The 5 sampled images are shown below:
    </p>
    <table border="1">
        <tr>
            <td>
                <img src="media5a/part1.5p1.jpg" style="width:300px;height:auto;" alt="part1.5p1.jpg">
                <img src="media5a/part1.5p2.jpg" style="width:300px;height:auto;" alt="part1.5p2.jpg">
            </td>
        </tr>
    </table>

    <h2> 1.6 Classifier-Free Guidance (CFG) </h2>
    <h3> Approach </h3>
    <p>
        To implement <code>iterative_denoise_cfg</code>, I edited my <code>iterative_denoise</code> function such that <code>noise_est = uncond_noise_est + scale * (noise_est - uncond_noise_est)</code>. Then, using the same procedure as 1.5, I generated random noise with <code>torch.randn</code> and applied my <code>iterative_denoise_cfg</code> function on it. The 5 sampled images are shown below:
    </p>
    <table border="1">
        <tr>
            <td>
                <img src="media5a/part1.6p1.jpg" style="width:300px;height:auto;" alt="part1.6p1.jpg">
                <img src="media5a/part1.6p2.jpg" style="width:300px;height:auto;" alt="part1.6p2.jpg">
            </td>
        </tr>
    </table>

    <h2> 1.7 Image-to-image Translation </h2>
    <h3> Approach </h3>
    <p>
        In this part, I applied the forward process to the test image, Kingaroo and Uniqloroo and applied my <code>iterative_denoise_cfg</code> function on it at the noise levels <code>[1, 3, 5, 7, 10, 20]</code>. The 5 sampled images are shown below:
    </p>
    <table border="1">
        <tr>
            <td>
                <img src="media5a/part1.7test1.jpg" style="width:300px;height:auto;" alt="part1.7test1.jpg">
                <img src="media5a/part1.7test2.jpg" style="width:300px;height:auto;" alt="part1.7test2.jpg">
                <div class="caption"> Test Image </div>
            </td>
            <td>
                <img src="media5a/part1.7kingaroo1.jpg" style="width:300px;height:auto;" alt="part1.7kingaroo1.jpg">
                <img src="media5a/part1.7kingaroo2.jpg" style="width:300px;height:auto;" alt="part1.7kingaroo2.jpg">
                <div class="caption"> Kingaroo </div>
            </td>
            <td>
                <img src="media5a/part1.7uniqloroo1.jpg" style="width:300px;height:auto;" alt="part1.7uniqloroo1.jpg">
                <img src="media5a/part1.7uniqloroo2.jpg" style="width:300px;height:auto;" alt="part1.7uniqloroo2.jpg">
                <div class="caption"> Uniqloroo </div>
            </td>
        </tr>
    </table>

    <h2> 1.7.1 Editing Hand-Drawn and Web Images </h2>
    <h3> Approach </h3>
    <p>
        In this part, I found an image online and drew two. Then, I passed the images through the starter code. The results are shown below:
    </p>
    <table border="1">
        <tr>
            <td>
                <img src="media5a/part1.7.1online.jpg" style="width:300px;height:auto;" alt="part1.7.1online.jpg">
                <div class="caption"> Online Image </div>
            </td>
            <td>
                <img src="media5a/part1.7.1handraw1edit.jpg" style="width:300px;height:auto;" alt="part1.7.1handraw1edit.jpg">
                <div class="caption"> Hand Drawn 1 </div>
            </td>
            <td>
                <img src="media5a/part1.7.1handraw2edit.jpg" style="width:300px;height:auto;" alt="part1.7.1handraw2edit.jpg">
                <div class="caption"> Hand Drawn 2 </div>
            </td>
        </tr>
    </table>

    <h2> 1.7.2 Inpainting </h2>
    <h3> Approach </h3>
    <p>
        In this part, I implemented the <code>inpaint</code> function by editing my <code>iterative_denoise_cfg</code> code to apply equation 5 on the project spec to account for the mask. The results are shown below (left is image and mask, right is inpainted):
    </p>
    <table border="1">
        <tr>
            <td>
                <img src="media5a/part1.7.2test.jpg" style="width:300px;height:auto;" alt="part1.7.2test.jpg">
                <img src="media5a/part1.7.2testedit.jpg" style="width:300px;height:auto;" alt="part1.7.2testedit.jpg">
                <div class="caption"> Test Image </div>
            </td>
            <td>
                <img src="media5a/part1.7.2kingaroo.jpg" style="width:300px;height:auto;" alt="part1.7.2kingaroo.jpg">
                <img src="media5a/part1.7.2kingarooedit.jpg" style="width:300px;height:auto;" alt="part1.7.2kingarooedit.jpg">
                <div class="caption"> Kingaroo </div>
            </td>
            <td>
                <img src="media5a/part1.7.2uniqloroo.jpg" style="width:300px;height:auto;" alt="part1.7.2uniqloroo.jpg">
                <img src="media5a/part1.7.2uniqlorooedit.jpg" style="width:300px;height:auto;" alt="part1.7.2uniqlorooedit.jpg">
                <div class="caption"> Uniqloroo </div>
            </td>
        </tr>
    </table>

    <h2> 1.7.3 Text-Conditional Image-to-image Translation </h2>
    <h3> Approach </h3>
    <p>
        In this part, I did the same as 1.7 but with the prompt <code>"a rocket ship"</code>. The results are below.
    </p>
    <table border="1">
        <tr>
            <td>
                <img src="media5a/part1.7.3test1.jpg" style="width:300px;height:auto;" alt="part1.7.3test1.jpg">
                <img src="media5a/part1.7.3test2.jpg" style="width:300px;height:auto;" alt="part1.7.3test2.jpg">
                <div class="caption"> Test Image </div>
            </td>
            <td>
                <img src="media5a/part1.7.3kingaroo1.jpg" style="width:300px;height:auto;" alt="part1.7.3kingaroo1.jpg">
                <img src="media5a/part1.7.3kingaroo2.jpg" style="width:300px;height:auto;" alt="part1.7.3kingaroo2.jpg">
                <div class="caption"> Kingaroo </div>
            </td>
            <td>
                <img src="media5a/part1.7.3uniqloroo1.jpg" style="width:300px;height:auto;" alt="part1.7.3uniqloroo1.jpg">
                <img src="media5a/part1.7.3uniqloroo2.jpg" style="width:300px;height:auto;" alt="part1.7.3uniqloroo2.jpg">
                <div class="caption"> Uniqloroo </div>
            </td>
        </tr>
    </table>

    <h2> 1.8 Visual Anagrams </h2>
    <h3> Approach </h3>
    <p>
        In this part, I implemented <code>make_flip_illusion</code> editing my <code>iterative_denoise_cfg</code> function to apply the equations on the project spec (to account for UNets and flipping). I then ran it on three different pairs of prompts, shown below:
    </p>
    <table border="1">
        <tr>
            <td>
                <img src="media5a/part1.8mancampfire.jpg" style="width:300px;height:auto;" alt="part1.8mancampfire.jpg">
            </td>
            <td>
                <img src="media5a/part1.8manhatpencil.jpg" style="width:300px;height:auto;" alt="part1.8manhatpencil.jpg">
            </td>
            <td>
                <img src="media5a/part1.8manrocket.jpg" style="width:300px;height:auto;" alt="part1.8manrocket.jpg">
            </td>
        </tr>
    </table>

    <h2> 1.9 Hybrid Images </h2>
    <h3> Approach </h3>
    <p>
        In this part, I implemented <code>make_hybrids</code> editing my <code>iterative_denoise_cfg</code> function to apply the equations on the project spec (to account for UNets and filtering). I then ran it on three different pairs of prompts, shown below:
    </p>
    <table border="1">
        <tr>
            <td>
                <img src="media5a/1.9skullwaterfall.jpg" style="width:300px;height:auto;" alt="1.9skullwaterfall.jpg">
                <div class="caption"> "a lithograph of a skull" and "a lithograph of waterfalls" </div>
            </td>
            <td>
                <img src="media5a/1.9pencilrocket.jpg" style="width:300px;height:auto;" alt="1.9pencilrocket.jpg">
                <div class="caption"> "a rocket ship" and "a pencil" </div>
            </td>
            <td>
                <img src="media5a/1.9hippiebaristavillage.jpg" style="width:300px;height:auto;" alt="1.9hippiebaristavillage.jpg">
                <div class="caption"> "an oil painting of a snowy mountain village" and "a photo of a hipster barista" </div>
            </td>
        </tr>
    </table>


    <h1> Project 5B: Diffusion Models From Scratch! </h1>

    <h2> Background </h2>
    <p>
        In this sub-project, we train diffusion models on MNIST datasets: Single-Step Denoising UNet, Time-Conditioning UNet and Class-Conditioning UNet.

        Credits to my CS189 Homework 6 from last semester for inspiring my code for training the models.
    </p>
    
    <h2> 1. Training a Single-Step Denoising UNet </h2>
    <h3> Approach </h3>
    <p>
        Using the skeleton code and the diagram in project spec provided, I implemented the <code>Conv</code> and <code>UnconditionalUNet</code> classes. I then created the functions <code>add_noise</code> and <code>add_noise_to_dataset</code> to assist with adding noise to an image and an entire dataset. I ran these functions with <code>sigma=[0.0, 0.2, 0.4, 0.6, 0.8, 1.0]</code> on the dataset. Then I trained the model on the MNIST dataset and sampled results on the test set after the first and the fifth epoch and with out-of-distribution noise levels after the model is trained. The results are shown below:
    </p>
    <table border="1">
        <tr>
            <td>
                <img src="media5b/fig3.jpg" style="width:300px;height:auto;" alt="fig3.jpg">
                <div class="caption"> Noising Process for Difference Sigmas </div>
            </td>
            <td>
                <img src="media5b/fig4.jpg" style="width:300px;height:auto;" alt="fig4.jpg">
                <div class="caption"> Training Loss Curve </div>
            </td>
        </tr>
        <tr>
            <td>
                <img src="media5b/fig5.jpg" style="width:300px;height:auto;" alt="fig5.jpg">
                <div class="caption"> Sample Results on the Test Set (Epoch 1) </div>
            </td>
            <td>
                <img src="media5b/fig6.jpg" style="width:300px;height:auto;" alt="fig6.jpg">
                <div class="caption"> Sample Results on the Test Set (Epoch 5) </div>
            </td>
            <td>
                <img src="media5b/fig7.jpg" style="width:300px;height:auto;" alt="fig7.jpg">
                <div class="caption"> Sample Results on the Test Set With Out-of-Distribution Noise Levels </div>
            </td>
        </tr>
        <tr>
            <td>
                <img src="media5b/fig7.jpg" style="width:300px;height:auto;" alt="fig7.jpg">
                <div class="caption"> Sample Results on the Test Set With Out-of-Distribution Noise Levels </div>
            </td>
        </tr>
    </table>

    <h2> 2. Training a Diffusion Model </h2>
    <h3> Time-Conditioning UNet </h3>
    <h3> Approach </h3>
    <p>
        Using the skeleton code and the diagram in project spec provided, I implemented the <code>FCBlock</code>, <code>TimeConditional</code> and <code>DDPM</code> classes, as well as the <code>ddpm_schedule</code>, <code>ddpm_forward</code> and <code>ddpm_sample</code>. Then I trained the model on the MNIST dataset and sampled results on the test set after the fifth and the twentieth epoch. The results are shown below:
    </p>
    <table border="1">
        <tr>
            <td>
                <img src="media5b/fig10.jpg" style="width:300px;height:auto;" alt="fig10.jpg">
                <div class="caption"> Training Loss Curve </div>
            </td>
            <td>
                <img src="media5b/tc5.jpg" style="width:300px;height:auto;" alt="tc5.jpg">
                <div class="caption"> Sample Results on the Test Set (Epoch 5) </div>
            </td>
            <td>
                <img src="media5b/tc20.jpg" style="width:300px;height:auto;" alt="tc20.jpg">
                <div class="caption"> Sample Results on the Test Set (Epoch 20) </div>
            </td>
        </tr>
    </table>

    <h3> Class-Conditioning UNet </h3>
    <h3> Approach </h3>
    <p>
        My process for this part was essentially identical to the previous, except I added two extra <code>FCBlock</code>s, as mentioned in the spec. Then I once again trained the model on the MNIST dataset and sampled results on the test set after the fifth and the twentieth epoch. The results are shown below:
    </p>
    <table border="1">
        <tr>
            <td>
                <img src="media5b/ccloss.jpg" style="width:300px;height:auto;" alt="ccloss.jpg">
                <div class="caption"> Training Loss Curve </div>
            </td>
            <td>
                <img src="media5b/cc5.jpg" style="width:300px;height:auto;" alt="cc5.jpg">
                <div class="caption"> Sample Results on the Test Set (Epoch 5) </div>
            </td>
            <td>
                <img src="media5b/cc20.jpg" style="width:300px;height:auto;" alt="cc20.jpg">
                <div class="caption"> Sample Results on the Test Set (Epoch 20) </div>
            </td>
        </tr>
    </table>
</body>
</html>
